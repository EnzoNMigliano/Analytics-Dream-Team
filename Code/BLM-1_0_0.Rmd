---
title: "Black Lives Matter - Analytics Dream Team"
author: "Adriana Ortiz, Enzo Novi Migliano, and Juan Zambrano"
output: html_notebook
---

# Abstract


The lives of African Americans have historically been disrespected. The treatment disparity of different ethnicities in the American society has a long and diverse scope. However, Under the following research question and problem statement: Do African Americans are significantly treated different in society than to other ethnicities in the United States? The presented study focused on the facets of the education, health, and law enforcement societal interaction. Through an archival analysis of governmental and public available data different statistical tests such as time series, linear and non-linear predictive models, and descriptive statistics will address the following hypothesis: **<THe hypothesis are missing>** . The current study provided great insight on the current situation of the Ethnical disparity of the American, as well possible solutions for the problem **<We Need to make a better COnclusion>**.


# Black Lives Matter

Black Lives Matter (BLM) is a movement that started as a hashtag for Twitter, and it has evolved to a political and social movement, aiming to visualize and intervene in violence inflicted on Black communities, under the BLM movements many protests have been promoted around the globe advocating against police violence towards black people. The main focus of the movement is to end with police brutality.

To understand the facts behind the claim of BLM, we are going to examine data from US authorities and how they treat people to assess if there is a difference in the way they treat Black Americans. The supporting data used towards this project comes from the US Census Bureau, New York Police Department, open data sources from some main metro US areas (Chicago, Dallas & LA), demographics including education, housing, and politics, and lastly data from the police authority. By using different statistical analysis techniques we aim to answer some questions such as how the police treatment towards black people has changed over the years, are African Americans being arrested more often than white, whats the group age seeing more disparity in police treatment among others.




# Method

## Data

The data utilized in the analysis was collected from different reliable sources (e.g., government, news papers, Kaggle). The data was collected in throughout the months of September and October of 2020, and the files were uploaded into an online repository in the web server "GitHub" (link to the online repository:
https://github.com/EnzoNMigliano/Analytics-Dream-Team).


## Instruments

### SOftware

In order to perform the analysis of the data we utilized the software R(Version 4.0.2) [1], emulated in the Rstudio(Version 1.3.1073) [2]. In order to perform the version control of the documents throughout the study, the team utilized the Software Git [3] in connection with the server of GitHub [4].

### Packages

In order to perform the analysis of the data we utilized the following packages: Tidyverse [5], Corrplot [6], CaTools [7], caret [8], and forecast [9].

#### Installing Necessary Packages

The code below is with hash tags to prevent people from installing the packages twice. If your computer does not have one of the packages below, please take way the hash tag and install the package at your convenience.

```{r}

# install.packages("tidyverse")
# install.packages("corrplot")
# install.packages("caTools")
# install.packeges("caret")
# install.packages("forecast")

```


#### Loading Necessary Libraries

The code below will load the installed packages into your Rstudio.

```{r}
library(tidyverse)
library(corrplot)
library(caTools)
library(caret)
library(forecast)
```

## Procedures

### Loading Data sets for the analysis

The code below will load all the data sets the team stored in the GitHub server.

```{r}
# Analytics-Dream-Team/Data

Covid_Deaths_Race <- read_csv("https://raw.githubusercontent.com/EnzoNMigliano/Analytics-Dream-Team/Backup/Data/Provisional_COVID-19_Death_Counts_by_County_and_Race_CDC_OCT1.csv")

All_Illness_Deaths_Rate <- read_csv("https://raw.githubusercontent.com/EnzoNMigliano/Analytics-Dream-Team/Backup/Data/Cumulative_Provisional_Counts_of_Deaths_by_Sex__Race__and_Age_CDC_AUG10.csv")

'2010&2011_Vadir_NY' <- read_csv("https://raw.githubusercontent.com/EnzoNMigliano/Analytics-Dream-Team/Backup/Data/2010-2011_VADIR_INCIDENTS-CITY_OF_NEW_YORK.csv")

'2012&2013_Vadir_NY' <- 
  read_csv("https://raw.githubusercontent.com/EnzoNMigliano/Analytics-Dream-Team/Backup/Data/2012-2013_VADIR_INCIDENTS-CITY_OF%20_NEW%20YORK.csv")

'2014&2015_Vadir_NY' <- 
  read_csv("https://raw.githubusercontent.com/EnzoNMigliano/Analytics-Dream-Team/Backup/Data/2014-2015_VADIR_INCIDENTS-CITY_OF_NEW_YORK.csv")

# Analytics-Dream-Team/Data/BLM Diverse Data/police_info/

Police_Budget <- read_csv("https://raw.githubusercontent.com/EnzoNMigliano/Analytics-Dream-Team/Backup/Data/BLM%20Diverse%20Data/police_info/budgets.csv")

Equipment_Police <- read_csv("https://raw.githubusercontent.com/EnzoNMigliano/Analytics-Dream-Team/Backup/Data/BLM%20Diverse%20Data/police_info/dod_equipment_purchases.csv")

Contract_Police <- read_csv("https://raw.githubusercontent.com/EnzoNMigliano/Analytics-Dream-Team/Backup/Data/BLM%20Diverse%20Data/police_info/police_contracts.csv")

Employment_FBI <- read_csv("https://media.githubusercontent.com/media/EnzoNMigliano/Analytics-Dream-Team/Backup/Data/BLM%20Diverse%20Data/police_info/police_employment_fbi.csv")

Police_Policies <- read_csv("https://raw.githubusercontent.com/EnzoNMigliano/Analytics-Dream-Team/Backup/Data/BLM%20Diverse%20Data/police_info/police_policies.csv")

# Analytics-Dream-Team/Data/BLM Diverse Data/demographics/

Poverty_Census <- read_csv("https://raw.githubusercontent.com/EnzoNMigliano/Analytics-Dream-Team/Backup/Data/BLM%20Diverse%20Data/demographics/poverty_census_bureau.csv")

Politics_538 <- read_csv("https://raw.githubusercontent.com/EnzoNMigliano/Analytics-Dream-Team/Backup/Data/BLM%20Diverse%20Data/demographics/politics_538.csv")

Housing <- read_csv("https://raw.githubusercontent.com/EnzoNMigliano/Analytics-Dream-Team/Backup/Data/BLM%20Diverse%20Data/demographics/housing.csv")

Eduction_Census <- read.csv("https://raw.githubusercontent.com/EnzoNMigliano/Analytics-Dream-Team/Backup/Data/BLM%20Diverse%20Data/demographics/education_census_bureau.csv")

# Analytics-Dream-Team/Data/BLM Diverse Data/crime_data/

Juvenile_Arrests <- read_csv("https://media.githubusercontent.com/media/EnzoNMigliano/Analytics-Dream-Team/Backup/Data/BLM%20Diverse%20Data/crime_data/juvenile_arrests.csv")

NYPD_Arrests <- read_csv("https://media.githubusercontent.com/media/EnzoNMigliano/Analytics-Dream-Team/Backup/Data/BLM%20Diverse%20Data/crime_data/NYPD_Arrests_Data__Historic_.csv")

LA_Crime <- read_csv("https://media.githubusercontent.com/media/EnzoNMigliano/Analytics-Dream-Team/Backup/Data/BLM%20Diverse%20Data/crime_data/LA%20Crime_Data_from_2010_to_2019.csv")

Dallas_Arrests <- read_csv("https://media.githubusercontent.com/media/EnzoNMigliano/Analytics-Dream-Team/Backup/Data/BLM%20Diverse%20Data/crime_data/Dallas%20Police%20Arrests.csv")

Chicago_Crimes_2011topresent <- 
  read_csv("https://media.githubusercontent.com/media/EnzoNMigliano/Analytics-Dream-Team/Backup/Data/BLM%20Diverse%20Data/crime_data/Chicago%20Crimes_-_2001_to_Present.csv")

# Analytics-Dream-Team/Data/BLM Diverse Data/NYC_stop_frisk/

NY_StopFrisk_2015 <- 
  read_csv("https://raw.githubusercontent.com/EnzoNMigliano/Analytics-Dream-Team/Backup/Data/BLM%20Diverse%20Data/NYC_stop_frisk/sqf-2015.csv")

NY_StopFrisk_2016 <- read_csv("https://raw.githubusercontent.com/EnzoNMigliano/Analytics-Dream-Team/Backup/Data/BLM%20Diverse%20Data/NYC_stop_frisk/sqf-2016.csv")

NY_StopFrisk_2017 <- read_csv("https://raw.githubusercontent.com/EnzoNMigliano/Analytics-Dream-Team/Backup/Data/BLM%20Diverse%20Data/NYC_stop_frisk/sqf-2017.csv")

  
Washington_post_Shootings <-
  read_csv("https://raw.githubusercontent.com/EnzoNMigliano/Analytics-Dream-Team/Backup/Data/shootings_wash_post.csv")

```



#### Brief description of the data sets

##### **VADIR_NY**


This is a conjunct of three data sets on reports of different schools according to its neighborhood in New York City. The reports range from fights to murder. There are three data sets with data collected by the local government of New York City from 2010 to 2015.


##### **All_Illnesses_Deaths_rate**


This data set is maintained by the Center of Disease Control and Prevention. It contains the most recent updated in all the most prevalent cause of deaths in the American society. THe data set is detailed and it gives the information regarding the different ethnicities in the American society.


##### **Chicago Crimes**


THis is incredible data set maintained by the local government from Chicago where it lists a detailed description of the crimes committed in the city of Chicago. THe data reported in the data set was collected from 2011 up to the most recent data collection.


##### **COntract_Police**


This data set maintained by the non governmental organization "Check the Police" lists the contract provisions with the police unions in the United States.

##### **Covid_Deaths_Race**


This data set maintained by the Center for Disease COntrol and Prevention lists the deaths by ethnicity in the united States up to August of 2020. 


##### **Dallas_Arrests**


This data set maintained by the local government of Dallas lists multiple information of arrest performed from 2014 to 2020 in the city of Dallas.

##### **Eduction_Census**


This Data maintained by the United States Census Bureau lists several indicators for the education in the United States. The data represents the most up to date available data from the Census Bureau. 

##### **Employment_FBI**


This data set maintained by the Federal Bureau of Investigation has information by the civilians employed in the law enforcement agencies, as the number of active officer in different regions of the United States.


##### **Equipment_police**


This data set is maintained by the Department of Defense 
and has information on most equipment purchases by State, City, and County. 

##### **Housing**

This data set is data set hosted by the Census Bureau and contains an approximate calculation of the housing occupancy, housing units, vacant units per state.

##### **Juvenile_Arrests**

This data set was created by Bureau of Justice, it reflects Juvenile Arrest rates sorted from 1980 to 2018.

##### **LA_Crime**

This data set was developed by the LA police departement and reflects all crime incidents in the city of Los Angeles from 2010 to 2020 In this data, it is specified the type of activity, location, victim, sex, age among other variables. 


##### **NY_StopFrisk_2015**


This data set was created by New York police department. It expoxes all stop and frisk activity in the City of New York in 2015.


##### **NY_StopFrisk_2016**

This data set was created by New York police department. It expoxes all stop and frisk activity in the City of New York in 2016.



##### **NY_StopFrisk_2017**

This data set was created by New York police department. It expoxes all stop and frisk activity in the City of New York in 2017.


##### **NY_StopFrisk_2018**


This data set was created by New York police department. It expoxes all stop and frisk activity in the City of New York in 2015.

##### **NY_StopFrisk_2016**

This data set was created by New York police department. It expoxes all stop and frisk activity in the City of New York in 2016.

##### **NY_StopFrisk_2017**

This data set was created by New York police department. It expoxes all stop and frisk activity in the City of New York in 2017.

##### **NYPD_Arrests**


This data set is a compilation of every arrest in NYC from 2006 until the end of 2018, some key variables are the type of ofense, the sex and the age group of the induvisula arrested.


##### **Police_Budget**


This dataset contais information about the finances for 150 large US ities across 120 categories including population, revenue per city and taxes.

####**Politics**
DataSet containing the political party inclination and segregation for metro areas.

####**Poverty Census**
The Dataset is about poverty levels by metro area.

####**Washinton Post Shootings**
This dataset contains names and data for citizens fatally shot by police.






### Tidying the Data Sets and exploring the data sets 

Data sets contain incredible value for the most diverse analysis. However, in order to complete extract such intrinsic value all data sets must be tidy, in order words, the data sets must organized in a logical manner for the analysis. In the next section all the tidying performed in the study is registered. In order to tidy the data, the team also explored it and got familiarized with data sets by using funciton such as View() and summary(). 


#### Tidying

This section contains the names of the data sets and it status regarding its organization.

##### **VADIR_NY**


In order to check if the data is tidy lets visualize the data set.

*2010-2011*

```{r}
View(`2010&2011_Vadir_NY`)
`2010&2011_Vadir_NY`
```

```{r}
summary(`2010&2011_Vadir_NY`)
```

*2012-2013*

```{r}
View(`2012&2013_Vadir_NY`)
`2012&2013_Vadir_NY`
```

```{r}
summary(`2012&2013_Vadir_NY`)

```

*2014-2015*

```{r}
View(`2014&2015_Vadir_NY`)
`2014&2015_Vadir_NY`
```

```{r}
summary(`2014&2015_Vadir_NY`)
```

All the New York Schools data sets are tidy, no further action required.


##### **All_Illnesses_Deaths_rate**


In order to check if the data is tidy lets visualize the data set.


```{r}
View(All_Illness_Deaths_Rate)
All_Illness_Deaths_Rate
```

```{r}
summary(All_Illness_Deaths_Rate)
```

This data set is tidy, no further action required.


##### **Chicago_Crimes**


In order to check if the data is tidy lets visualize the data set.


```{r}
Chicago_Crimes_2011topresent
```


The Chicago Crimes 2011 to present is not Tidy yet. The variable "Date" has two values the date and time, as well as "Updated On". Therefore, we need to separate the values into two cells. One cell will be for the variable date and the other will be for the variable time. 

```{r}
# This code will fix the variable "Date"

ChicagoTidy <-
  Chicago_Crimes_2011topresent %>%
  separate(Date,
           into = c("Day",
                    "Time"),
           sep = " ")
```


```{r}
# This code will rm the varible "Updated on"

ChicagoTidy2 <- within(ChicagoTidy, rm('Updated On'))
```

*The Tidy data set*


The tidy data set will be called ChigagoTidy2. In such data set we separed the values that were present in the same cell. Therefore, the variables "Date" and "Updated On" were dived into four new variables.The variable "Date" into the variables "Day" and "Time". The variable "Updated On" into the variables "Updated_Date" and "Updated_Time". See the new data set below:


```{r}
ChicagoTidy2
```


##### **Contract_Police**

There are, however some observaitons that are NA.

```{r}
summary(ChicagoTidy2)
```
The code below will rename the observations that were NA:

```{r}
  
ChicagoTidyFinal <- ChicagoTidy2 %>%
  replace_na(list( 'X Coordinate' = "Missing",
                    'Y Coordinate' = "Missing",
                    Latitude ="Missing", 
                   Longitude = "Missing",
                   Location = "Missing"))

```

The data is now tidy, no further action. See below:

```{r}
ChicagoTidyFinal
```




##### **COntract_Police**


In order to check if the data is tidy lets visualize the data set.

```{r}
View(Contract_Police)
Contract_Police
```
```{r}
summary(Contract_Police)
```

This data set is tidy, no further action required.


##### **Covid_Deaths_Race**


In order to check if the data is tidy lets visualize the data set.


```{r}
view(Covid_Deaths_Race)
Covid_Deaths_Race
```

```{r}
summary(Covid_Deaths_Race)
```


There are some observations with NA. However, We cannot change such observations. 


This data set is tidy, no further action required.


##### **Dallas_Arrests**


In order to check if the data is tidy lets visualize the data set.

```{r}
View(Dallas_Arrests)
Dallas_Arrests
```


The Dallas Arrest Data set is not tidy yet. The data data set has some variables with two values in one cell. For example,  the observations of the variable "ArArrestDate" have two values per cell the day and the time. Therefore, we need to separate the values into to new complete variables. 

```{r}
# This code will fix all the variables "ArArrestDate" and "ArBkDate"

DallasArrestTidy <-
  Dallas_Arrests %>%
  separate(ArArrestDate,
           into = c("ArArrestDay",
                    "ArArrestTime"),
           sep = " ") %>%
  separate(ArBkDate,
           into = c("ArBkDay",
                    "ArBkTime"),
           sep = " ")
```

*The tidy data set*

The tidy data set will be called "DallasArrestTidy". In such data set, we transformed through the code above the variable (of the original data set) "ArArrestDate" into the variables "ArArrestDay" and "ArArrestTime" (in the tidy data set), also we the transformed the variable "ArBkDate" (of the original data set) into the variables "ArBkDay" and "ArBkTime" (in the tidy data set). See the new data set below:

```{r}
summary(DallasArrestTidy)
```



```{r}
DallasArrestTidy
```






##### **Eduction_Census**


In order to check if the data is tidy lets visualize the data set.

```{r}
View(Eduction_Census)
Eduction_Census
```


The data set Education Census is not tidy yet. There is one column that cointaing two different types of observations. The variable "Geographic.Area.Name" has three observations in it there is the name of the city, the State, and the classification of the city. Therefore, we need to separate those observations into completly new variables by assign it to new columns.

```{r}

Education_Census_Tidy <- Eduction_Census %>%
  separate(Geographic.Area.Name,
           into = c("CityName",
                    "StateName"),
           sep = ", ") %>%
  separate(StateName,
           into = c("State",
                    "Area"),
           sep = " ")

```


*The tidy data set*

The tidy data set will be called "Education_Census_Tidy". In such data set, we transformed through the code above the variable (of the original data set) "Geographic.Area.Name" into the variables "CityName", "State", and "Area"(in the tidy data set). See the new data set below:


```{r}
Education_Census_Tidy
```


##### **Employment_FBI**


In order to check if the data is tidy lets visualize the data set.


```{r}
View(Employment_FBI)
Employment_FBI
```

This data set is tidy, no further action required.

##### **Equitment_Police**

In order to check if the data is tidy lets visualize the data set.

```{r}
view(Equipment_Police)
```

##### **Housing**

In order to check if the data is tidy lets visualize the data set.

##### **Equitment_Police**

In order to check if the data is tidy lets visualize the data set.

```{r}
view(Equipment_Police)
Equipment_Police
```

This data set is tidy, no further action required.


##### **Housing**

In order to check if the data is tidy lets visualize the data set.


```{r}
view(Housing)
Housing
```

This data set is tidy, no further action required.


##### **Juvenile_Arrests**

In order to check if the data is tidy lets visualize the data set.

```{r}
view(Juvenile_Arrests)
Juvenile_Arrests
```

This data set is tidy, no further action required.


##### **LA_Crime**

In order to check if the data is tidy lets visualize the data set.

```{r}

LA_Crime
```


This data set is tidy, no further action required.


#### **NY_StopFrisk_2015**

In order to check if the data is tidy lets visualize the data sets.

```{r}
view(NY_StopFrisk_2015)


NY_StopFrisk_2015
```

We are subseting the data with relevant values

```{r}
NY_StopFrisk_2015Tidy <- NY_StopFrisk_2015 %>% subset(select = c(year, datestop, crimsusp, explnstp, 
                                                                  offunif, frisked, searched, contrabn,pf_hcuff, forceuse, sex, race, age, ht_feet, weight, build, city)) %>% rename(Year = year, `Date of Frisk` = datestop,`Crime Suspected` = crimsusp, `Officer Explained Reason` = explnstp, `Officer Wearing Uniform` = offunif, Frisked = frisked, `Body Searched` = searched, Contraband = contrabn, `Hanfcuff Used` = pf_hcuff, `Force Used` = forceuse, Sex = sex, Race = race, Age = age, Height = ht_feet, Weight = weight, `Body Type` = build, City = city)

NY_StopFrisk_2015Tidy

```

This data set is tidy, no further action required.


#### **NY_StopFrisk_2016**

In order to check if the data is tidy lets visualize the data sets.

```{r}
view(NY_StopFrisk_2016)

```

We are subseting the data with relevant values

```{r}
NY_StopFrisk_2016Tidy <- NY_StopFrisk_2016 %>% subset(select = c(year, datestop, crimsusp, explnstp, 
                                                                  offunif, frisked, searched, contrabn,pf_hcuff, forceuse, sex, race, age, ht_feet, weight, build, city)) %>% rename(Year = year, `Date of Frisk` = datestop,`Crime Suspected` = crimsusp, `Officer Explained Reason` = explnstp, `Officer Wearing Uniform` = offunif, Frisked = frisked, `Body Searched` = searched, Contraband = contrabn, `Hanfcuff Used` = pf_hcuff, `Force Used` = forceuse, Sex = sex, Race = race, Age = age, Height = ht_feet, Weight = weight, `Body Type` = build, City = city)
                 

NY_StopFrisk_2016Tidy$Age <- as.double(NY_StopFrisk_2016Tidy$Age)                    

NY_StopFrisk_2016Tidy

```

This data set is tidy, no further action required.


#### **NY_StopFrisk_2017**


In order to check if the data is tidy lets visualize the data sets.

```{r}
view(NY_StopFrisk_2017)
NY_StopFrisk_2017
```


We are subseting the data with relevant values

```{r}
NY_StopFrisk_2017Tidy <- NY_StopFrisk_2017 %>% subset(select = c(YEAR2, STOP_FRISK_DATE,SUSPECTED_CRIME_DESCRIPTION, OFFICER_EXPLAINED_STOP_FLAG, 
                                                                  OFFICER_IN_UNIFORM_FLAG, FRISKED_FLAG, SEARCHED_FLAG, OTHER_CONTRABAND_FLAG,
                                                                 PHYSICAL_FORCE_HANDCUFF_SUSPECT_FLAG, PHYSICAL_FORCE_RESTRAINT_USED_FLAG, SUSPECT_SEX, SUSPECT_RACE_DESCRIPTION, 
                                                                 SUSPECT_REPORTED_AGE, SUSPECT_HEIGHT, SUSPECT_WEIGHT, SUSPECT_BODY_BUILD_TYPE, STOP_LOCATION_BORO_NAME)) %>% rename(Year = YEAR2,`Date of Frisk` = STOP_FRISK_DATE,`Crime Suspected` = SUSPECTED_CRIME_DESCRIPTION, `Officer Explained Reason` = OFFICER_EXPLAINED_STOP_FLAG, `Officer Wearing Uniform` = OFFICER_IN_UNIFORM_FLAG, Frisked = FRISKED_FLAG, `Body Searched` = SEARCHED_FLAG, Contraband = OTHER_CONTRABAND_FLAG, `Hanfcuff Used` = PHYSICAL_FORCE_HANDCUFF_SUSPECT_FLAG, `Force Used` = PHYSICAL_FORCE_RESTRAINT_USED_FLAG, Sex = SUSPECT_SEX, Race = SUSPECT_RACE_DESCRIPTION, Age = SUSPECT_REPORTED_AGE, Height = SUSPECT_HEIGHT, Weight = SUSPECT_WEIGHT, `Body Type` = SUSPECT_BODY_BUILD_TYPE, City = STOP_LOCATION_BORO_NAME)
                                                                  
                                                         

NY_StopFrisk_2017Tidy
```


This data set is tidy, no further action required.



##### **Juvenile_Arrests**

THis data set is tidy.

```{r}
view(Juvenile_Arrests)
```


##### **LA_Crime**

In order to check if the data is tidy lets visualize the data set.

```{r}
view(LA_Crime)
```

This data set is tidy, no further action required.


#### **NYPD_Arrests**

In order to check if the data is tidy lets visualize the data sets.


```{r}
NYPD_Arrests
```


The data set contains some rows missing the description of the type and categoriztion of the arrest which we will change to undetermined or 0 (zero) to keep observation in the analysis. The new tidyed data set will be called NewNYPD.


```{r}
NewNYPD<- NYPD_Arrests%>%
  replace_na(list(designation="Missing", PD_DESC = "Undertermined", OFNS_DESC="Undertermined", KY_CD="0"))
NewNYPD
```

####**Police Budget**

Data contains missing observations when the city does not percive income per the variable item. , but is tidy

```{r}
Police_Budget
```


####**Politics**

Data is tidy.

```{r}
Politics_538
```

####**Poverty Census**

The data set is tidy.

```{r}
Poverty_Census
```


####**Washinton Post Shootings**

The data set is tidy.
 
```{r}
Washington_post_Shootings

```






### Merging Relational Data

The data collected for the study has several distinct data sets. Some data sets, however, have an intrinsic relation with each other, in other words they have a relation in the observations that they recorded. For example, the data sets about the stop and frisk in New York City are almost the same, the difference is the time in which the observations were recorded (i.e., the year in which it was recorded). Therefore, such data sets can be merged into one for a more meaningful analysis with more observations. The current study merged the following data sets together:



#### **VADIR_NY**

First we will observe the three different data sets:

```{r}
`2010&2011_Vadir_NY`
```

In specific the county variable of each one of the data sets

```{r}
`2010&2011_Vadir_NY` %>% group_by(County) %>% summarise(count = n())
```
```{r}
`2012&2013_Vadir_NY` %>% group_by(County) %>% summarise(count = n())
```

```{r}
`2014&2015_Vadir_NY` %>% group_by(County) %>% summarise(count = n())
```
 There are some variables to rename in the first two data sets, they are the same observations but had different names at different times. See the code below:
 
 
These are the variables of 2010 that were not matched in the data of 2014.

```{r}
`2010&2011_Vadir_NY`[`2010&2011_Vadir_NY`$County == "BRONX"
  , c("County")] <- "Bronx"
```

```{r}
`2010&2011_Vadir_NY`[`2010&2011_Vadir_NY`$County == "NYC CENTRAL OFFICE"
  , c("County")] <- "New York"
```

```{r}
`2010&2011_Vadir_NY`[`2010&2011_Vadir_NY`$County == "BROOKLYN"
  , c("County")] <- "Kings"
```

```{r}
`2010&2011_Vadir_NY`[`2010&2011_Vadir_NY`$County == "MANHATTAN"
  , c("County")] <- "New York"
```

```{r}
`2010&2011_Vadir_NY`[`2010&2011_Vadir_NY`$County == "QUEENS"
  , c("County")] <- "Queens"
```

```{r}
`2010&2011_Vadir_NY`[`2010&2011_Vadir_NY`$County == "RICHMOND"
  , c("County")] <- "Richmond"
```

These are the variables of 2012 that were not matched in the data of 2014.

```{r}
`2012&2013_Vadir_NY`[`2012&2013_Vadir_NY`$County == "Nyc Central Office"
  , c("County")] <- "New York"
```

This data set the same variables being observed over a few years. Therefore, it can be merged into one data set, as bellow:

```{r}
Vadir_NY <- full_join(`2010&2011_Vadir_NY`, `2012&2013_Vadir_NY`)

Vadir_NY_Join <- full_join(Vadir_NY, `2014&2015_Vadir_NY`)
```

The new data set merged all the observations from 2010 to 2015 since it had the same column names (variable names). The new data set is called "Vadir_NY_Join" as below:


```{r}
Vadir_NY_Join
```


#### **NY_StopFrisk_Merged**

```{r}

```



We are merging the data sets as they are equal both in rows and columns. First 2015 and 2016



```{r}
NY_StopFrisk1 <- full_join(NY_StopFrisk_2015Tidy, NY_StopFrisk_2016Tidy)
```

```{r}
NY_StopFrisk1
```


Then, the merged data set with 2017


In order to do so, there some issues between the data sets regarding its compatibility. THerefore, the colunm were fixed with the code below:

```{r}
NY_StopFrisk1$`Day Of Frisk` <-  str_sub(NY_StopFrisk1$`Date of Frisk`, 1, 2)
NY_StopFrisk1$`Date of Friskm` <-  NY_StopFrisk1$`Date of Frisk`
str_sub(NY_StopFrisk1$`Date of Friskm`, 2, 2) <- "0"
str_sub(NY_StopFrisk1$`Date of Friskm`, 1, 1) <- "-"
NY_StopFrisk1$`Month Of Frisk` <-  str_sub(NY_StopFrisk1$`Date of Friskm`, 1, 3)
NY_StopFrisk1$`Date of Frisky` <-  NY_StopFrisk1$`Date of Frisk`
str_sub(NY_StopFrisk1$`Date of Frisky`, 3, 3) <- "-"
NY_StopFrisk1$`Year Of Frisk` <-  str_sub(NY_StopFrisk1$`Date of Frisky`, 3, 7)
```


THe data set from 2017 has the variable "Date of Frisk " separated by - and in the order of year, month, and day. Therefore, we need to fix the variable "Date of Frisk" in the "Ny_StopFrisk1" so it able to merge both data sets.

In the code above we divided the variable from "Ny_StopFrisk1" in to day, month and year. Later we substituted the one of the number of the string in another variable so it would be similar to the format in the 2017 data set that contains"-".



```{r}
NY_StopFrisk1
```


Now that all the variables are in the right pieces of the original variable, the function unite was utilized to unite the columns with the values from the original "Date of Frisk", but now in the same formar as is in 2017. See the code below:

```{r}
NY_StopFrisk1_1 <-
  NY_StopFrisk1 %>%
  unite(`Date of Frisk`,`Year Of Frisk`, `Month Of Frisk`,`Day Of Frisk`, `Year Of Frisk`) %>% 
  select(Year, `Date of Frisk`, `Crime Suspected`, `Officer Explained Reason`, `Officer Wearing Uniform`, Frisked, `Body Searched`, Contraband, `Hanfcuff Used`, `Force Used`, Sex, Race, Age, Height, Weight, `Body Type`, City)
```

```{r}
NY_StopFrisk1_1
```

```{r}
NY_StopFrisk1_1$`Date of Frisk` <- str_remove(NY_StopFrisk1_1$`Date of Frisk`, "-")
NY_StopFrisk1_1$`Date of Frisk` <- str_remove(NY_StopFrisk1_1$`Date of Frisk`, "_")
NY_StopFrisk1_1$`Date of Friskd` <- str_sub(NY_StopFrisk1_1$`Date of Frisk`, 8,10 ) 
str_sub(NY_StopFrisk1_1$`Date of Friskd`, 1, 1) <- "-"
NY_StopFrisk1_1$`Date of FriskGOOD` <- str_sub(NY_StopFrisk1_1$`Date of Frisk`, 1,7 ) 
NY_StopFrisk1_1F <- NY_StopFrisk1_1 %>%
  unite(`Date of Frisk`, `Date of FriskGOOD`, `Date of Friskd`  )
```

```{r}
NY_StopFrisk1_1F
```

```{r}
NY_StopFrisk1_1F$`Date of Frisk` <- str_remove(NY_StopFrisk1_1F$`Date of Frisk`, "_")

```

```{r}
NY_StopFrisk1_1F
```


```{r}
NY_StopFrisk_2017Tidy
```



```{r}
NY_StopFrisk_2017Tidy$Age <- as.double(NY_StopFrisk_2017Tidy$Age)
NY_StopFrisk_2017Tidy$Height <- as.double(NY_StopFrisk_2017Tidy$Height)
NY_StopFrisk_2017Tidy$Weight <- as.double(NY_StopFrisk_2017Tidy$Weight)
```

```{r}
NY_StopFrisk_2017Tidy$`Date of Frisk` <- as.character(NY_StopFrisk_2017Tidy$`Date of Frisk`)
NY_StopFrisk_2017Tidy$`Date of Frisk` <- as.character(NY_StopFrisk_2017Tidy$`Date of Frisk`)

```



```{r}
NY_StopFrisk2 <- full_join(NY_StopFrisk1_1F, NY_StopFrisk_2017Tidy)

```

```{r}
NY_StopFrisk2
```



# Results

For the analysis our team utilized an alpha of 0.05.

## **In New York incidents in schools happen significantly more frequent in neighborhoods were there more African Americans**

Therefore our Hypothesis are:

H0 - There is no significant difference

HA - There is a significant difference


### Exploratory analysis

The team performed an exploratory analysis of the tidy and merged data sets in order to get familiarized with the information available in the data sets. The exploratory analysis is strongly related with the results section of the present study.


### Exploring the problem

We will create a new column in the vadir_NY_Join called "TotalIncidents"

```{r}
Vadir_NY_Join$TotalIncidents <- rowSums(Vadir_NY_Join[ ,c(10:45)])
Vadir_NY_Join$TotalIncidents
```

Now lets vizualize how is the distribution of the incidents per count:


```{r}
Vadir_NY_Join %>% group_by(County) %>% 
  ggplot(mapping = aes(x = TotalIncidents, fill =  County)) + 
  geom_histogram() +
  labs(title = "Number of Incidents per count",
       subtitle = "New York Schools",
       x = "Number of observations",
       y = "Number of Incidents",
       caption = "Source: New York City")
```


```{r}
Vadir_NY_Join %>% group_by(County) %>% 
  ggplot(mapping = aes(x = TotalIncidents, fill =  County)) + 
  geom_boxplot() +
  labs(title = "Number of Incidents per count",
       subtitle = "New York Schools",
       x = "Observations",
       y = "Counts",
       caption = "Source: New York City")
```

As we can observe the incidents are somewhat different in the different counts. Therefore, more analysis is required for further explanation of the differences.


### Exploring with numbers

```{r}
Vadir_NY_Join %>% group_by(County) %>% 
  select(TotalIncidents) %>%
  na.omit() %>%
  summarize(avgExtra = mean(TotalIncidents),
            sdExtra = sd(TotalIncidents),
            count = n())
```

The mean values and the standard deviation of the variables give a better understanding of how each county struggles with incidents such drug trafficking, robbery, and violence in general.

### Cheking for normality


Before we test the hypothesis that the number of incidents reported is different, it is necessery define if the data sets being analyzed are normally distributed.

For the statistical test we will compare the Bronx which 36% of its pupolation is African American and Richmond which 98% of its population is caucasian according to the last census. 


**Bronx**

Lets see if how is the distrbution of the incidents in the Bronx.

```{r}
TotalBronkx <- Vadir_NY_Join %>%
  select(County, TotalIncidents) %>%
  filter(County == "Bronx") %>%
  na.omit()
```


```{r}
shapiro.test(TotalBronkx$TotalIncidents)
```

The observations of the incidents in the Bronx are not normally distributed. The P-value is lower than the alpha (0.05).
<all the coding with explanations>

<results>



# conclusion


**<We need a conclusion>**

# Refences


[1]  R Core Team (2020). R: A language and
  environment for statistical computing. R
  Foundation for Statistical Computing,
  Vienna, Austria. URL
  https://www.R-project.org/.
  
[2] RStudio Team (2020). RStudio: Integrated           Development for R. RStudio, PBC, Boston, MA URL      http://www.rstudio.com/.

[3] Software Freedom Conservancy, Inc., 2020. [Online]. Available: https://git-scm.com/

[4] GitHub, Inc., 2020. [Online]. Available: https://github.com/

[5] Wickham et al., (2019). Welcome to the
  tidyverse. Journal of Open Source
  Software, 4(43), 1686,
  https://doi.org/10.21105/joss.01686

[6] Taiyun Wei and Viliam Simko (2017). R
  package "corrplot": Visualization of a
  Correlation Matrix (Version 0.84).
  Available from
  https://github.com/taiyun/corrplot


[7] Jarek Tuszynski (2020). caTools: Tools:
  Moving Window Statistics, GIF, Base64,
  ROC AUC, etc. R package version 1.18.0.
  https://CRAN.R-project.org/package=caTools

[8] Max Kuhn (2020). caret: Classification
  and Regression Training. R package
  version 6.0-86.
  https://CRAN.R-project.org/package=caret


[9] Hyndman R, Athanasopoulos G, Bergmeir C,
  Caceres G, Chhay L, O'Hara-Wild M,
  Petropoulos F, Razbash S, Wang E, Yasmeen F
  (2020). _forecast: Forecasting functions
  for time series and linear models_. R
  package version 8.13, <URL:
  https://pkg.robjhyndman.com/forecast/>.
  
  

